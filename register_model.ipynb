{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Eliminar \"Second Experiment\" desde la UI.\n",
    "2. En la terminal: `# rm -rf mlruns/.trash/*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar 4 modelos diferentes:\n",
    "1. Regresi√≥n Log√≠stica\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. XGBoost con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "classes, counts = np.unique(y_train_res, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        LogisticRegression(C=1, solver='liblinear'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"C\": 1, \"solver\": \"liblinear\"}\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"n_estimators\": 30, \"max_depth\": 3}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\"}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\", \"resampling\": \"SMOTE\"}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set, params in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(model_name, \"\\n\", report)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Vamos a registrar las m√©tricas y modelos en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Second Experiment\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    X_train, y_train = element[2]\n",
    "    X_test, y_test = element[3]\n",
    "    params = element[4]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):   \n",
    "        # Log de hiperpar√°metros y nombre del modelo     \n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log de todas las m√©tricas\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric_name, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric_name}\", value)\n",
    "            else:\n",
    "                mlflow.log_metric(label, metrics)\n",
    "                \n",
    "        # Log del dataset\n",
    "        X_train_df = pd.DataFrame(X_train, columns=[f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "        X_train_df[\"label\"] = y_train\n",
    "        dataset_path = f\"data/train_dataset_{model_name.replace(' ', '_')}.csv\"\n",
    "        X_train_df.to_csv(dataset_path, index=False)\n",
    "        mlflow.log_artifact(dataset_path, artifact_path=\"datasets\")\n",
    "        mlflow.set_tag(\"dataset\", \"with_smote\") if \"SMOTE\" in model_name else mlflow.set_tag(\"dataset\", \"original\")\n",
    "\n",
    "        # Log del modelo\n",
    "        input_example = pd.DataFrame(X_test[:2], columns=[f\"feature_{i}\" for i in range(X.shape[1])])    \n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \n",
    "                                     \"model\", \n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \n",
    "                                     \"model\",\n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Registrar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'XGB-Smote' # Unique way to call our model\n",
    "run_id=input('Please type RunID')\n",
    "model_uri = f'runs:/{run_id}/model'\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Si corremos la celda anterior nuevamente, vamos a estar cambiando de versi√≥n al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üè∑Ô∏è Aliases comunes en el Model Registry\n",
    "\n",
    "Cuando registramos modelos en el **Model Registry** de MLflow, podemos asignarles **etiquetas (aliases)** para indicar su rol dentro del ciclo de vida del proyecto.\n",
    "\n",
    "Algunos alias comunes:\n",
    "\n",
    "- **Champion**: es el **modelo actual en producci√≥n**, el mejor hasta el momento.\n",
    "- **Challenger**: es un **modelo nuevo que compite** con el Champion. Se lo entrena y eval√∫a para ver si lo supera.\n",
    "- **Staging**: modelo en etapa de pruebas, listo para ser validado antes de pasarlo a producci√≥n.\n",
    "- **Archived**: modelos viejos que ya no se usan, pero que quedan guardados para referencia o auditor√≠a.\n",
    "\n",
    "üí° Usar estos nombres no es obligatorio, pero es una **convenci√≥n muy √∫til** para que todo el equipo entienda r√°pidamente el rol de cada modelo registrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generar predicciones con el modelo *Challenger*\n",
    "\n",
    "Ahora vamos a cargar el modelo que registramos como **Challenger** desde el **Model Registry** de MLflow y vamos a **testearlo localmente**.\n",
    "\n",
    "Esto nos permite, por ejemplo:\n",
    "- Validar su performance con datos nuevos\n",
    "- Compararlo contra el modelo actual en producci√≥n (el *Champion*)\n",
    "- Decidir si vale la pena promoverlo a producci√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opcion usando el alias en lugar del model_version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"models:/{model_name}@challenger\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transicionar el modelo a Producci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos MLflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_model_uri = f\"models:/{model_name}@challenger\"\n",
    "production_model_name = \"anomaly-detection-prod\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=dev_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Ahora le podemos dar un alias en la UI, como `\"champion\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Una vez que ya tenemos identificado y probado nuestro modelo Champion, podr√≠amos por ejemplo, empaquetarlo dentro de un contenedor Docker.\n",
    "\n",
    "Adem√°s, hay muchas plataformas que **integran nativamente con MLflow**, como por ejemplo:\n",
    "\n",
    "- **Databricks**\n",
    "- **AWS SageMaker**\n",
    "- **Azure ML**\n",
    "- **Google Cloud Vertex AI**\n",
    "- Y otras plataformas open source que aceptan modelos MLflow.\n",
    "\n",
    "Esto nos permite tener un flujo de trabajo completo: desde la experimentaci√≥n hasta el despliegue, todo trazable y reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚û°Ô∏è Una vez que ya le di el alias @champion, genero predicciones con el modelo en producci√≥n \n",
    "model_version = 1\n",
    "prod_model_uri = f\"models:/{production_model_name}@champion\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
