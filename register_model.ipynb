{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 0: 90.0% (900 muestras)\n",
      "Clase 1: 10.0% (100 muestras)\n"
     ]
    }
   ],
   "source": [
    "# Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 0: 50.0% (630 muestras)\n",
      "Clase 1: 50.0% (630 muestras)\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "classes, counts = np.unique(y_train_res, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar 4 modelos diferentes:\n",
    "1. Regresión Logística\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. XGBoost con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        LogisticRegression(C=1, solver='liblinear'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"C\": 1, \"solver\": \"liblinear\"}\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"n_estimators\": 30, \"max_depth\": 3}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\"}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\", \"resampling\": \"SMOTE\"}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      " {'0': {'precision': 0.9454545454545454, 'recall': 0.9629629629629629, 'f1-score': 0.9541284403669725, 'support': 270.0}, '1': {'precision': 0.6, 'recall': 0.5, 'f1-score': 0.5454545454545454, 'support': 30.0}, 'accuracy': 0.9166666666666666, 'macro avg': {'precision': 0.7727272727272727, 'recall': 0.7314814814814814, 'f1-score': 0.749791492910759, 'support': 300.0}, 'weighted avg': {'precision': 0.9109090909090909, 'recall': 0.9166666666666666, 'f1-score': 0.91326105087573, 'support': 300.0}}\n",
      "Random Forest \n",
      " {'0': {'precision': 0.96415770609319, 'recall': 0.9962962962962963, 'f1-score': 0.9799635701275046, 'support': 270.0}, '1': {'precision': 0.9523809523809523, 'recall': 0.6666666666666666, 'f1-score': 0.7843137254901961, 'support': 30.0}, 'accuracy': 0.9633333333333334, 'macro avg': {'precision': 0.9582693292370712, 'recall': 0.8314814814814815, 'f1-score': 0.8821386478088503, 'support': 300.0}, 'weighted avg': {'precision': 0.9629800307219661, 'recall': 0.9633333333333334, 'f1-score': 0.9603985856637737, 'support': 300.0}}\n",
      "XGBClassifier \n",
      " {'0': {'precision': 0.9781818181818182, 'recall': 0.9962962962962963, 'f1-score': 0.9871559633027523, 'support': 270.0}, '1': {'precision': 0.96, 'recall': 0.8, 'f1-score': 0.8727272727272727, 'support': 30.0}, 'accuracy': 0.9766666666666667, 'macro avg': {'precision': 0.969090909090909, 'recall': 0.8981481481481481, 'f1-score': 0.9299416180150125, 'support': 300.0}, 'weighted avg': {'precision': 0.9763636363636364, 'recall': 0.9766666666666667, 'f1-score': 0.9757130942452044, 'support': 300.0}}\n",
      "XGBClassifier With SMOTE \n",
      " {'0': {'precision': 0.9812734082397003, 'recall': 0.9703703703703703, 'f1-score': 0.9757914338919925, 'support': 270.0}, '1': {'precision': 0.7575757575757576, 'recall': 0.8333333333333334, 'f1-score': 0.7936507936507936, 'support': 30.0}, 'accuracy': 0.9566666666666667, 'macro avg': {'precision': 0.869424582907729, 'recall': 0.9018518518518519, 'f1-score': 0.8847211137713931, 'support': 300.0}, 'weighted avg': {'precision': 0.9589036431733061, 'recall': 0.9566666666666667, 'f1-score': 0.9575773698678726, 'support': 300.0}}\n"
     ]
    }
   ],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set, params in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(model_name, \"\\n\", report)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': {'precision': 0.9454545454545454,\n",
       "   'recall': 0.9629629629629629,\n",
       "   'f1-score': 0.9541284403669725,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.6,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.5454545454545454,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9166666666666666,\n",
       "  'macro avg': {'precision': 0.7727272727272727,\n",
       "   'recall': 0.7314814814814814,\n",
       "   'f1-score': 0.749791492910759,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9109090909090909,\n",
       "   'recall': 0.9166666666666666,\n",
       "   'f1-score': 0.91326105087573,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.96415770609319,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9799635701275046,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.9523809523809523,\n",
       "   'recall': 0.6666666666666666,\n",
       "   'f1-score': 0.7843137254901961,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9633333333333334,\n",
       "  'macro avg': {'precision': 0.9582693292370712,\n",
       "   'recall': 0.8314814814814815,\n",
       "   'f1-score': 0.8821386478088503,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9629800307219661,\n",
       "   'recall': 0.9633333333333334,\n",
       "   'f1-score': 0.9603985856637737,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9781818181818182,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9871559633027523,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.96,\n",
       "   'recall': 0.8,\n",
       "   'f1-score': 0.8727272727272727,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9766666666666667,\n",
       "  'macro avg': {'precision': 0.969090909090909,\n",
       "   'recall': 0.8981481481481481,\n",
       "   'f1-score': 0.9299416180150125,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9763636363636364,\n",
       "   'recall': 0.9766666666666667,\n",
       "   'f1-score': 0.9757130942452044,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9812734082397003,\n",
       "   'recall': 0.9703703703703703,\n",
       "   'f1-score': 0.9757914338919925,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.7575757575757576,\n",
       "   'recall': 0.8333333333333334,\n",
       "   'f1-score': 0.7936507936507936,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9566666666666667,\n",
       "  'macro avg': {'precision': 0.869424582907729,\n",
       "   'recall': 0.9018518518518519,\n",
       "   'f1-score': 0.8847211137713931,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9589036431733061,\n",
       "   'recall': 0.9566666666666667,\n",
       "   'f1-score': 0.9575773698678726,\n",
       "   'support': 300.0}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Vamos a registrar las métricas y modelos en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_label_encoder': False, 'eval_metric': 'logloss', 'resampling': 'SMOTE'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/26 14:50:11 INFO mlflow.tracking.fluent: Experiment with name 'Second Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: http://localhost:5000/#/experiments/422036461495027387/runs/19c2ce1c07b54852888a54c2ec4a913a\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/422036461495027387\n",
      "🏃 View run Random Forest at: http://localhost:5000/#/experiments/422036461495027387/runs/290ab4a614fa41ec9f15a2f5b54e4e5d\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/422036461495027387\n",
      "🏃 View run XGBClassifier at: http://localhost:5000/#/experiments/422036461495027387/runs/540c2b37a171441d99eeab7a1ec9e6b1\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/422036461495027387\n",
      "🏃 View run XGBClassifier With SMOTE at: http://localhost:5000/#/experiments/422036461495027387/runs/fbed176f05ca4baaa8f52513ecabfcc2\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/422036461495027387\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Second Experiment\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    X_train, y_train = element[2]\n",
    "    X_test, y_test = element[3]\n",
    "    params = element[4]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):   \n",
    "        # Log de hiperparámetros y nombre del modelo     \n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log de todas las métricas\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric_name, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric_name}\", value)\n",
    "            else:\n",
    "                mlflow.log_metric(label, metrics)\n",
    "                \n",
    "        # Log del dataset\n",
    "        X_train_df = pd.DataFrame(X_train, columns=[f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "        X_train_df[\"label\"] = y_train\n",
    "        dataset_path = f\"data/train_dataset_{model_name.replace(' ', '_')}.csv\"\n",
    "        X_train_df.to_csv(dataset_path, index=False)\n",
    "        mlflow.log_artifact(dataset_path, artifact_path=\"datasets\")\n",
    "        mlflow.set_tag(\"dataset\", \"with_smote\") if \"SMOTE\" in model_name else mlflow.set_tag(\"dataset\", \"original\")\n",
    "\n",
    "        # Log del modelo\n",
    "        input_example = pd.DataFrame(X_test[:2], columns=[f\"feature_{i}\" for i in range(X.shape[1])])    \n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \n",
    "                                     \"model\", \n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \n",
    "                                     \"model\",\n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Registrar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'XGB-Smote'.\n",
      "2025/03/26 15:27:08 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB-Smote, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBClassifier With SMOTE at: http://localhost:5000/#/experiments/422036461495027387/runs/fbed176f05ca4baaa8f52513ecabfcc2\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/422036461495027387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'XGB-Smote'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'XGB-Smote' # Unique way to call our model\n",
    "run_id=input('Please type RunID')\n",
    "model_uri = f'runs:/{run_id}/model'\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 Si corremos la celda anterior nuevamente, vamos a estar cambiando de versión al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏷️ Aliases comunes en el Model Registry\n",
    "\n",
    "Cuando registramos modelos en el **Model Registry** de MLflow, podemos asignarles **etiquetas (aliases)** para indicar su rol dentro del ciclo de vida del proyecto.\n",
    "\n",
    "Algunos alias comunes:\n",
    "\n",
    "- **Champion**: es el **modelo actual en producción**, el mejor hasta el momento.\n",
    "- **Challenger**: es un **modelo nuevo que compite** con el Champion. Se lo entrena y evalúa para ver si lo supera.\n",
    "- **Staging**: modelo en etapa de pruebas, listo para ser validado antes de pasarlo a producción.\n",
    "- **Archived**: modelos viejos que ya no se usan, pero que quedan guardados para referencia o auditoría.\n",
    "\n",
    "💡 Usar estos nombres no es obligatorio, pero es una **convención muy útil** para que todo el equipo entienda rápidamente el rol de cada modelo registrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generar predicciones con el modelo *Challenger*\n",
    "\n",
    "Ahora vamos a cargar el modelo que registramos como **Challenger** desde el **Model Registry** de MLflow y vamos a **testearlo localmente**.\n",
    "\n",
    "Esto nos permite, por ejemplo:\n",
    "- Validar su performance con datos nuevos\n",
    "- Compararlo contra el modelo actual en producción (el *Champion*)\n",
    "- Decidir si vale la pena promoverlo a producción\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opcion usando el alias en lugar del model_version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri = f\"models:/{model_name}@challenger\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transicionar el modelo a Producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos MLflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'anomaly-detection-prod'.\n",
      "Copied version '1' of model 'XGB-Smote' to version '1' of model 'anomaly-detection-prod'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1743014400280, current_stage='None', description='', last_updated_timestamp=1743014400280, name='anomaly-detection-prod', run_id='fbed176f05ca4baaa8f52513ecabfcc2', run_link='', source='models:/XGB-Smote/1', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_model_uri = f\"models:/{model_name}@challenger\"\n",
    "production_model_name = \"anomaly-detection-prod\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=dev_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Ahora le podemos dar un alias en la UI, como `\"champion\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Una vez que ya tenemos identificado y probado nuestro modelo Champion, podríamos por ejemplo, empaquetarlo dentro de un contenedor Docker.\n",
    "\n",
    "Además, hay muchas plataformas que **integran nativamente con MLflow**, como por ejemplo:\n",
    "\n",
    "- **Databricks**\n",
    "- **AWS SageMaker**\n",
    "- **Azure ML**\n",
    "- **Google Cloud Vertex AI**\n",
    "- Y otras plataformas open source que aceptan modelos MLflow.\n",
    "\n",
    "Esto nos permite tener un flujo de trabajo completo: desde la experimentación hasta el despliegue, todo trazable y reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ➡️ Una vez que ya le di el alias @champion, genero predicciones con el modelo en producción \n",
    "model_version = 1\n",
    "prod_model_uri = f\"models:/{production_model_name}@champion\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
