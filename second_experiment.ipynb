{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar 4 modelos diferentes:\n",
    "1. Regresi√≥n Log√≠stica\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. XGBoost con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "classes, counts = np.unique(y_train_res, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        LogisticRegression(C=1, solver='liblinear'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"C\": 1, \"solver\": \"liblinear\"}\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"n_estimators\": 30, \"max_depth\": 3}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\"}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\", \"resampling\": \"SMOTE\"}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set, params in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(model_name, \"\\n\", report)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Vamos a registrar las m√©tricas y modelos en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Second Experiment\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    X_train, y_train = element[2]\n",
    "    X_test, y_test = element[3]\n",
    "    params = element[4]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):   \n",
    "        # Log de hiperpar√°metros y nombre del modelo     \n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log de todas las m√©tricas\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric_name, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric_name}\", value)\n",
    "            else:\n",
    "                mlflow.log_metric(label, metrics)\n",
    "                \n",
    "        # Log del dataset\n",
    "        X_train_df = pd.DataFrame(X_train, columns=[f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "        X_train_df[\"label\"] = y_train\n",
    "        dataset_path = f\"data/train_dataset_{model_name.replace(' ', '_')}.csv\"\n",
    "        X_train_df.to_csv(dataset_path, index=False)\n",
    "        mlflow.log_artifact(dataset_path, artifact_path=\"datasets\")\n",
    "        mlflow.set_tag(\"dataset\", \"with_smote\") if \"SMOTE\" in model_name else mlflow.set_tag(\"dataset\", \"original\")\n",
    "\n",
    "        # Log del modelo\n",
    "        input_example = pd.DataFrame(X_test[:2], columns=[f\"feature_{i}\" for i in range(X.shape[1])])    \n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \n",
    "                                     \"model\", \n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \n",
    "                                     \"model\",\n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ¬°Listo! Tu experimento y los 4 runs se registraron correctamente en MLflow üéâ\n",
    "\n",
    "Podemos comparar la performance de nuestros modelos desde la UI:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"imgs/mlflow_2.png\" alt=\"Compare Runs MLflow\" width=\"900\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
