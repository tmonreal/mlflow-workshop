{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 0: 90.0% (900 muestras)\n",
      "Clase 1: 10.0% (100 muestras)\n"
     ]
    }
   ],
   "source": [
    "# Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 0: 50.0% (630 muestras)\n",
      "Clase 1: 50.0% (630 muestras)\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "classes, counts = np.unique(y_train_res, return_counts=True)\n",
    "total = counts.sum()\n",
    "percentages = (counts / total) * 100\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Clase 0: {percentages[0]:.1f}% ({counts[0]} muestras)\")\n",
    "print(f\"Clase 1: {percentages[1]:.1f}% ({counts[1]} muestras)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar 4 modelos diferentes:\n",
    "1. Regresi√≥n Log√≠stica\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. XGBoost con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        LogisticRegression(C=1, solver='liblinear'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"C\": 1, \"solver\": \"liblinear\"}\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"n_estimators\": 30, \"max_depth\": 3}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\"}\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test),\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": \"logloss\", \"resampling\": \"SMOTE\"}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      " {'0': {'precision': 0.9454545454545454, 'recall': 0.9629629629629629, 'f1-score': 0.9541284403669725, 'support': 270.0}, '1': {'precision': 0.6, 'recall': 0.5, 'f1-score': 0.5454545454545454, 'support': 30.0}, 'accuracy': 0.9166666666666666, 'macro avg': {'precision': 0.7727272727272727, 'recall': 0.7314814814814814, 'f1-score': 0.749791492910759, 'support': 300.0}, 'weighted avg': {'precision': 0.9109090909090909, 'recall': 0.9166666666666666, 'f1-score': 0.91326105087573, 'support': 300.0}}\n",
      "Random Forest \n",
      " {'0': {'precision': 0.9607142857142857, 'recall': 0.9962962962962963, 'f1-score': 0.9781818181818182, 'support': 270.0}, '1': {'precision': 0.95, 'recall': 0.6333333333333333, 'f1-score': 0.76, 'support': 30.0}, 'accuracy': 0.96, 'macro avg': {'precision': 0.9553571428571428, 'recall': 0.8148148148148149, 'f1-score': 0.8690909090909091, 'support': 300.0}, 'weighted avg': {'precision': 0.9596428571428572, 'recall': 0.96, 'f1-score': 0.9563636363636364, 'support': 300.0}}\n",
      "XGBClassifier \n",
      " {'0': {'precision': 0.9781818181818182, 'recall': 0.9962962962962963, 'f1-score': 0.9871559633027523, 'support': 270.0}, '1': {'precision': 0.96, 'recall': 0.8, 'f1-score': 0.8727272727272727, 'support': 30.0}, 'accuracy': 0.9766666666666667, 'macro avg': {'precision': 0.969090909090909, 'recall': 0.8981481481481481, 'f1-score': 0.9299416180150125, 'support': 300.0}, 'weighted avg': {'precision': 0.9763636363636364, 'recall': 0.9766666666666667, 'f1-score': 0.9757130942452044, 'support': 300.0}}\n",
      "XGBClassifier With SMOTE \n",
      " {'0': {'precision': 0.9812734082397003, 'recall': 0.9703703703703703, 'f1-score': 0.9757914338919925, 'support': 270.0}, '1': {'precision': 0.7575757575757576, 'recall': 0.8333333333333334, 'f1-score': 0.7936507936507936, 'support': 30.0}, 'accuracy': 0.9566666666666667, 'macro avg': {'precision': 0.869424582907729, 'recall': 0.9018518518518519, 'f1-score': 0.8847211137713931, 'support': 300.0}, 'weighted avg': {'precision': 0.9589036431733061, 'recall': 0.9566666666666667, 'f1-score': 0.9575773698678726, 'support': 300.0}}\n"
     ]
    }
   ],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set, params in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(model_name, \"\\n\", report)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': {'precision': 0.9454545454545454,\n",
       "   'recall': 0.9629629629629629,\n",
       "   'f1-score': 0.9541284403669725,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.6,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.5454545454545454,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9166666666666666,\n",
       "  'macro avg': {'precision': 0.7727272727272727,\n",
       "   'recall': 0.7314814814814814,\n",
       "   'f1-score': 0.749791492910759,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9109090909090909,\n",
       "   'recall': 0.9166666666666666,\n",
       "   'f1-score': 0.91326105087573,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9607142857142857,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9781818181818182,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.95,\n",
       "   'recall': 0.6333333333333333,\n",
       "   'f1-score': 0.76,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.96,\n",
       "  'macro avg': {'precision': 0.9553571428571428,\n",
       "   'recall': 0.8148148148148149,\n",
       "   'f1-score': 0.8690909090909091,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9596428571428572,\n",
       "   'recall': 0.96,\n",
       "   'f1-score': 0.9563636363636364,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9781818181818182,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9871559633027523,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.96,\n",
       "   'recall': 0.8,\n",
       "   'f1-score': 0.8727272727272727,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9766666666666667,\n",
       "  'macro avg': {'precision': 0.969090909090909,\n",
       "   'recall': 0.8981481481481481,\n",
       "   'f1-score': 0.9299416180150125,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9763636363636364,\n",
       "   'recall': 0.9766666666666667,\n",
       "   'f1-score': 0.9757130942452044,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9812734082397003,\n",
       "   'recall': 0.9703703703703703,\n",
       "   'f1-score': 0.9757914338919925,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.7575757575757576,\n",
       "   'recall': 0.8333333333333334,\n",
       "   'f1-score': 0.7936507936507936,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9566666666666667,\n",
       "  'macro avg': {'precision': 0.869424582907729,\n",
       "   'recall': 0.9018518518518519,\n",
       "   'f1-score': 0.8847211137713931,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9589036431733061,\n",
       "   'recall': 0.9566666666666667,\n",
       "   'f1-score': 0.9575773698678726,\n",
       "   'support': 300.0}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Vamos a registrar las m√©tricas y modelos en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_label_encoder': False, 'eval_metric': 'logloss', 'resampling': 'SMOTE'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Logistic Regression at: http://localhost:5000/#/experiments/931683556860607386/runs/e6ffcc7970954c4585c25be2dc14377d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/931683556860607386\n",
      "üèÉ View run Random Forest at: http://localhost:5000/#/experiments/931683556860607386/runs/0021020fd45b4989a762d6e7b9a5de41\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/931683556860607386\n",
      "üèÉ View run XGBClassifier at: http://localhost:5000/#/experiments/931683556860607386/runs/61e3f973294744df97be7c1a172883f6\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/931683556860607386\n",
      "üèÉ View run XGBClassifier With SMOTE at: http://localhost:5000/#/experiments/931683556860607386/runs/f4762dd8fc88437c86d3d5f1b0ced465\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/931683556860607386\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Second Experiment\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    X_train, y_train = element[2]\n",
    "    X_test, y_test = element[3]\n",
    "    params = element[4]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):   \n",
    "        # Log de hiperpar√°metros y nombre del modelo     \n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log de todas las m√©tricas\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric_name, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric_name}\", value)\n",
    "            else:\n",
    "                mlflow.log_metric(label, metrics)\n",
    "                \n",
    "        # Log del dataset\n",
    "        X_train_df = pd.DataFrame(X_train, columns=[f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "        X_train_df[\"label\"] = y_train\n",
    "        dataset_path = f\"data/train_dataset_{model_name.replace(' ', '_')}.csv\"\n",
    "        X_train_df.to_csv(dataset_path, index=False)\n",
    "        mlflow.log_artifact(dataset_path, artifact_path=\"datasets\")\n",
    "        mlflow.set_tag(\"dataset\", \"with_smote\") if \"SMOTE\" in model_name else mlflow.set_tag(\"dataset\", \"original\")\n",
    "\n",
    "        # Log del modelo\n",
    "        input_example = pd.DataFrame(X_test[:2], columns=[f\"feature_{i}\" for i in range(X.shape[1])])    \n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \n",
    "                                     \"model\", \n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \n",
    "                                     \"model\",\n",
    "                                     input_example = input_example, \n",
    "                                     signature = signature)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf mlruns/.trash/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ¬°Listo! Tu experimento y los 4 runs se registraron correctamente en MLflow üéâ\n",
    "\n",
    "Podemos comparar la performance de nuestros modelos desde la UI:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"imgs/mlflow_2.png\" alt=\"Compare Runs MLflow\" width=\"900\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
